{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767a90ad-cc02-4dac-97a7-a4ba4a27280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow #big module for NN creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0d16f5-da7e-4ba5-aeea-28f71e97cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create cnn first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b774e5c7-0043-4f44-8025-d58fe3dd9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8e25fa-11de-45cc-ac07-1f0684a91655",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d2b729-b124-42df-ac40-1e35448d49c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(32,(3,3),input_shape = (64,64,3), activation='relu')) \n",
    "#input_shape = (64,64,3) -> this limits the picture size to 64*64 pixels and 3 color channels\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(16,(3,3), activation='relu')) \n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b0afdc-42fd-4b23-b729-63ab69b38b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation='relu'))\n",
    "cnn.add(Dense(32,activation='relu'))\n",
    "cnn.add(Dense(16,activation='relu'))\n",
    "cnn.add(Dense(8,activation='relu'))\n",
    "cnn.add(Dense(4,activation='relu'))\n",
    "cnn.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d0f8e3-cf4e-4526-bb0b-16df726195de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce0f12f-4f09-4a46-a3ce-39f97065e109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - loss: 0.6934 - val_loss: 0.6929\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - loss: 0.6929 - val_loss: 0.6924\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - loss: 0.6927 - val_loss: 0.6930\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: 0.6929 - val_loss: 0.6921\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 0.6899 - val_loss: 0.7230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1802985a210>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for codes syntax we can google keras python documentation -> .flow_from_directory()\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\ACER\\OneDrive\\Desktop\\github_clones\\DL_study\\dataset\\training_set\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\ACER\\OneDrive\\Desktop\\github_clones\\DL_study\\dataset\\test_set\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50,\n",
    "        epochs=5,\n",
    "        validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7fa0b-d5b7-469f-8110-de8f9d843daf",
   "metadata": {},
   "source": [
    "# Now for the testing of how the model works for new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3beea94-2302-4733-984d-f487392c1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3beaf5c-4018-4d83-8113-1dafb4562910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img(r\"C:\\Users\\ACER\\OneDrive\\Desktop\\github_clones\\DL_study\\dataset\\single_prediction\\cat_or_dog_1.jpg\", target_size=(64,64))\n",
    "img = image.load_img(r\"C:\\Users\\ACER\\OneDrive\\Desktop\\github_clones\\DL_study\\dataset\\single_prediction\\cat_or_dog_2.jpg\", target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb289d97-3345-4da1-858e-ca26a0e806d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d640be1-a031-458c-b655-391413a9dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        ...,\n",
       "        [245., 245., 245.],\n",
       "        [245., 245., 245.],\n",
       "        [245., 245., 245.]],\n",
       "\n",
       "       [[239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        ...,\n",
       "        [245., 245., 245.],\n",
       "        [245., 245., 245.],\n",
       "        [244., 244., 244.]],\n",
       "\n",
       "       [[239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        [239., 239., 239.],\n",
       "        ...,\n",
       "        [244., 244., 244.],\n",
       "        [244., 244., 244.],\n",
       "        [244., 244., 244.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[241., 217., 205.],\n",
       "        [243., 220., 206.],\n",
       "        [242., 219., 205.],\n",
       "        ...,\n",
       "        [226., 201., 181.],\n",
       "        [233., 205., 193.],\n",
       "        [232., 215., 197.]],\n",
       "\n",
       "       [[255., 236., 229.],\n",
       "        [251., 234., 227.],\n",
       "        [252., 235., 227.],\n",
       "        ...,\n",
       "        [219., 193., 178.],\n",
       "        [219., 193., 178.],\n",
       "        [216., 189., 172.]],\n",
       "\n",
       "       [[243., 230., 224.],\n",
       "        [250., 235., 228.],\n",
       "        [245., 232., 226.],\n",
       "        ...,\n",
       "        [203., 180., 164.],\n",
       "        [220., 198., 177.],\n",
       "        [225., 202., 186.]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2998dab-8e63-49bf-9476-4e410e0185c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now first flattening before using it in cnn\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74516265-b1c0-4016-837e-c3e63eadc53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "p = cnn.predict(img) # the output is either greater or less than 0.5 because we have used sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "152c2076-9b30-46c7-8c22-e49852c578ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "if p[0][0] < 0.5:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d035f09-4559-46ee-ada2-84c825c98d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
